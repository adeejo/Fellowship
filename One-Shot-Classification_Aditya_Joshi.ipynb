{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will be creating a Siamese Network in keras on the Omniglot dataset as part of the Fellowship.ai challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###Loading the libraries###\n",
    "###I have used the https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d\n",
    "### to help me with this challenge\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, merge\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "import numpy.random as rng\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A function to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading a Images into variable. The images are letters from each different alphabets and they are stored in a numpy array.\n",
    "## My computer was taking too long to load the entire training dataset(characters) so I loaded a subset of the characters\n",
    "##Input: Path of the file\n",
    "##Output: A numpy Stacked 3d array of images for each alphabet and their respective letters\n",
    "def loadFile(path):\n",
    "    character_path = {}\n",
    "    n = 0\n",
    "    X = []\n",
    "    y = []\n",
    "    for alphabet in os.listdir(path):\n",
    "        print (alphabet)\n",
    "        for character in os.listdir(path+'/'+alphabet):\n",
    "\n",
    "            character_images= []\n",
    "            character_path[n] = (alphabet,character)\n",
    "            for image in os.listdir(path+'/'+alphabet+'/'+character):\n",
    "\n",
    "                image_read = io.imread(path+'/'+alphabet+'/'+character+'/'+image)\n",
    "\n",
    "                character_images.append(image_read)\n",
    "                y.append(n)\n",
    "\n",
    "                \n",
    "            n= n+1;\n",
    "\n",
    "            X.append(np.stack(character_images))\n",
    "\n",
    "    X = np.stack(X)\n",
    "    return X, np.vstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Set\n",
      "\n",
      "---------------------\n",
      "\n",
      "Alphabet_of_the_Magi\n",
      "Anglo-Saxon_Futhorc\n",
      "Arcadian\n",
      "Armenian\n",
      "Asomtavruli_(Georgian)\n",
      "Balinese\n",
      "Bengali\n",
      "Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
      "Braille\n",
      "Burmese_(Myanmar)\n",
      "Cyrillic\n",
      "Early_Aramaic\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading Evaluation set\n",
      "\n",
      "---------------------\n",
      "\n",
      "Angelic\n",
      "Atemayar_Qelisayer\n",
      "Atlantean\n",
      "Aurek-Besh\n",
      "Avesta\n",
      "Ge_ez\n",
      "Glagolitic\n",
      "Gurmukhi\n",
      "Kannada\n",
      "Keble\n",
      "Malayalam\n",
      "Manipuri\n",
      "Mongolian\n",
      "Old_Church_Slavonic_(Cyrillic)\n",
      "Oriya\n",
      "Sylheti\n",
      "Syriac_(Serto)\n",
      "Tengwar\n",
      "Tibetan\n",
      "ULOG\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading Training Set\") \n",
    "print(\"\\n---------------------\\n\")\n",
    "\n",
    "X,y=loadFile(\"D:\\\\Users\\\\npjos\\\\Documents\\\\Code\\\\Python\\\\images_background\\\\images_background\")\n",
    "\n",
    "print(\"\\n---------------------\\n\")\n",
    "print (\"Loading Evaluation set\")\n",
    "print(\"\\n---------------------\\n\")\n",
    "\n",
    "Xval,yval = loadFile(\"D:\\\\Users\\\\npjos\\\\Documents\\\\Code\\\\Python\\\\images_evaluation\\\\images_evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly initalizing weights to the appropriate shape\n",
    "def initialize_weights(shape, name=None):\n",
    "\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "#setting bias to zero\n",
    "def initialize_bias(shape, name=None):\n",
    "\n",
    "\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since a one shot classification was to be implemented in which only one training example for each class is used\n",
    "#a Siamese network was choosen based on literature. There are other distance based algorithms(ex.nearest neighbour) that can identify \n",
    "## similarities between two images, but they seem to have higer error rates.\n",
    "#A siamese Network are two Convolutional Neural Networks that are two copies of the same network. \n",
    "#Two input images are passed through the same network. \n",
    "\n",
    "\n",
    "#Creating a 5 layered convolution network\n",
    "#Input: shape of the images\n",
    "#Output: A model based on the shape\n",
    "def simaese_model(input_shape):\n",
    "    model = Sequential()\n",
    "    right = Input(shape=input_shape)\n",
    "    left = Input(shape=input_shape)\n",
    "    ### 5 layered convolution network\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    encoded_l = model(left)\n",
    "    encoded_r = model(right)\n",
    "    \n",
    "    def l1_distance(x): \n",
    "        return K.abs(x[0] - x[1])\n",
    "\n",
    "    def l1_distance_shape(x): \n",
    "        print(x)\n",
    "        return x[0]\n",
    "    \n",
    "    \n",
    "    L1_layer = Lambda(l1_distance)\n",
    "    \n",
    "    merged_model = L1_layer([encoded_l, encoded_r])    \n",
    "    \n",
    "    \n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(merged_model)\n",
    "    \n",
    "    siamese = Model(inputs=[left,right],outputs=prediction)\n",
    "    \n",
    "    return siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\npjos\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "    model = simaese_model((105, 105, 1))  \n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=Adam(lr=0.00006))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a batch with half the pairs with same letter and other half with different letters(chosen randomly)\n",
    "#Input: Size of the batch size and the image array\n",
    "#Output: 1: A pair of letters with same letters and another half with different letters \n",
    "#        Also \n",
    "def create_batch(batch_size,X):\n",
    "    n_languages, n_characters, w, h = X.shape\n",
    "    categories = rng.choice(n_languages,size=(batch_size,),replace=False)\n",
    "    \n",
    "    pairs=[np.zeros((batch_size, h, w,1)) for i in range(2)]\n",
    "    targets=np.zeros((batch_size,))\n",
    "    first_half_batch = int (batch_size/2)\n",
    "    \n",
    "    for i in range(first_half_batch) :\n",
    "        category = categories[i]\n",
    "        idx_1 = rng.randint(0, n_characters)\n",
    "        \n",
    "        pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "        \n",
    "        idx_2 = rng.randint(0, n_characters)\n",
    "        pairs[1][i,:,:,:] = X[category,idx_2].reshape(w, h,1)\n",
    "     \n",
    "    ##Second half of the batch with different letters\n",
    "    for i in range(first_half_batch, batch_size): \n",
    "        category = categories[i]\n",
    "        pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "       \n",
    "        \n",
    "        idx_2 = rng.randint(0, n_characters)\n",
    "        cat2 = get_second_pair_index(category,n_languages)\n",
    "                #cat = category +1\n",
    "    pairs[1][i,:,:,:] = X[cat2,idx_2].reshape(w, h,1)\n",
    "    #first half of the images have the same pairs of letters\n",
    "    targets[:batch_size//2] = 1\n",
    "    return pairs, targets\n",
    "\n",
    "#ensure that 2nd pair is from different language\n",
    "def get_second_pair_index(category,n_languages):\n",
    "    j = 0\n",
    "    cat2 = 0\n",
    "    while (j < 100):\n",
    "        j = j +1\n",
    "        cat2 = rng.randint(1,n_languages)\n",
    "                \n",
    "        if  (cat2 != category):\n",
    "            j = 101\n",
    "        elif(j ==100):\n",
    "            cat2 = category-1 if (category == n_languages) else category + 1\n",
    "        \n",
    "    return cat2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a one shot task based on the number of clases to test\n",
    "#Input the X variable and number of number of classes\n",
    "def make_one_shot(X,N):\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    categories = rng.choice(range(n_classes),size=(N,),replace=False)\n",
    "\n",
    "    \n",
    "    indices = rng.randint(0, n_examples,size=(N,))  \n",
    "    \n",
    "    true_category = categories[0]   \n",
    "    ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "    indices[0] = ex2\n",
    "    \n",
    "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
    "    \n",
    "    support_set = X[categories,indices,:,:]\n",
    "    support_set = support_set.reshape(N, w, h,1)\n",
    "    \n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    \n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image,support_set]\n",
    "    return pairs,targets\n",
    "\n",
    "#Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\n",
    "def test_oneshot(model, N, k, X, verbose = 0):\n",
    "    \n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_one_shot(X,N)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "    percent_correct = (100.0 * n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_every = 50 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 250 # of training iterations\n",
    "N_way = 20 # of alphabets for testing one-shot tasks\n",
    "n_val = 50# of one-shot tasks to validate on\n",
    "best = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for every 10th iteration: 0.62622496287028 mins\n",
      "Time for every 20th iteration: 1.2000741283098857 mins\n",
      "Time for every 30th iteration: 1.7722429434458415 mins\n",
      "Time for every 40th iteration: 2.4052831133206687 mins\n",
      "Time for every 50th iteration: 2.992612055937449 mins\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 50 iterations: 2.992612055937449 mins\n",
      "Train Loss: 0.668337881565094\n",
      "Evaluating model on 50 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 6.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 6.0, previous best: 0\n",
      "Time for every 60th iteration: 4.101039238770803 mins\n",
      "Time for every 70th iteration: 4.6795917510986325 mins\n",
      "Time for every 80th iteration: 5.251346556345622 mins\n",
      "Time for every 90th iteration: 5.820407021045685 mins\n",
      "Time for every 100th iteration: 6.402649633089701 mins\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 100 iterations: 6.402649633089701 mins\n",
      "Train Loss: 0.6410543322563171\n",
      "Evaluating model on 50 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 0.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Time for every 110th iteration: 7.4134509563446045 mins\n",
      "Time for every 120th iteration: 7.989958997567495 mins\n",
      "Time for every 130th iteration: 8.597965979576111 mins\n",
      "Time for every 140th iteration: 9.191359496116638 mins\n",
      "Time for every 150th iteration: 9.872281241416932 mins\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 150 iterations: 9.872364366054535 mins\n",
      "Train Loss: 0.5871154069900513\n",
      "Evaluating model on 50 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 12.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 12.0, previous best: 6.0\n",
      "Time for every 160th iteration: 11.000636847813924 mins\n",
      "Time for every 170th iteration: 11.579538416862487 mins\n",
      "Time for every 180th iteration: 12.245341722170512 mins\n",
      "Time for every 190th iteration: 12.900394713878631 mins\n",
      "Time for every 200th iteration: 13.534296627839407 mins\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 200 iterations: 13.534329875310261 mins\n",
      "Train Loss: 0.5637156963348389\n",
      "Evaluating model on 50 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 14.0% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 14.0, previous best: 12.0\n",
      "Time for every 210th iteration: 14.743304487069448 mins\n",
      "Time for every 220th iteration: 15.385121202468872 mins\n",
      "Time for every 230th iteration: 16.06130007505417 mins\n",
      "Time for every 240th iteration: 16.72608856757482 mins\n",
      "Time for every 250th iteration: 17.359527583916982 mins\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 250 iterations: 17.359527583916982 mins\n",
      "Train Loss: 0.4278756380081177\n",
      "Evaluating model on 50 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 12.0% 20 way one-shot learning accuracy \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''  Training the model using the pairs of images. \n",
    "Note half of the pairs have matching letters and other half have mismatch letters '''\n",
    "\n",
    "### The average is going to be much lower since it takes over 40 minutes to train over 500 iterations. \n",
    "###So I have chosen to evaluate 250 iterations. \n",
    "###If model was trained on the cloud I could train for longer iterations and receive a higher accuracy\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "        (inputs,targets) = create_batch(batch_size,X)\n",
    "        loss = model.train_on_batch(inputs, targets)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print (\"Time for every {0}th iteration: {1} mins\".format(i,(time.time()-t_start)/60.0))\n",
    "        if i % evaluate_every == 0:\n",
    "           print(\"\\n ------------- \\n\")\n",
    "           print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "           print(\"Train Loss: {0}\".format(loss)) \n",
    "           val_acc = test_oneshot(model, N_way, n_val,X,verbose=True)\n",
    "           \n",
    "           if val_acc >= best:\n",
    "                print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "                model.save_weights('my_model_training_weights.h5')\n",
    "                best = val_acc\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' getting a matrix of images for the validation task'''\n",
    "def concat_images(X):\n",
    "\n",
    "    nc, h , w, _ = X.shape\n",
    "    X = X.reshape(nc, h, w)\n",
    "    n = 2\n",
    "    img = np.zeros((2*105,5*105))\n",
    "\n",
    "    k = 0\n",
    "    for i in range(n):\n",
    "       for j in range (5):\n",
    "           \n",
    "           img[i*105:105*(i+1),j*105:105*(j+1)] = X[k]\n",
    "           k=k+1;\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target letter is stored in 8 index\n",
      "The predicted match letter is stored in 0 index\n",
      "(10, 105, 105)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.05, 'The validation tasks')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Purpose of this figure is to show the accuracy of the training model\n",
    "### In this block of code we are showing the test image letter and comparing it against 10 other letters. \n",
    "###One letters in the validation tasks are the same test image\n",
    "pairs, target = make_one_shot(X,10)\n",
    "index_target = np.argmax(target)\n",
    "print(\"The target letter is stored in {0} index\".format(index_target))\n",
    "probs = model.predict(pairs)\n",
    "index_prediction = np.argmax(probs)\n",
    "print(\"The predicted match letter is stored in {0} index\".format(index_prediction))\n",
    "    \n",
    "fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "ax1.matshow(pairs[0][0].reshape(105,105))\n",
    "ax1.set_title(\"The test image\")\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xticks([])\n",
    "img = concat_images(pairs[1]) \n",
    "ax2.matshow(img)\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_title(\"The validation tasks\")\n",
    "\n",
    "\n",
    "### In this example the model was not able to identify the target letter. The corresponding test image is stored in the \n",
    "#8th index(2nd row 4th column) and the model choose the 0th index (1st row, 1st column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = np.arange(1,10,2)\n",
    "trials = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs, train_accs, = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin the evaluation stage of the training and testing data\n",
      "Testing data accuracy on training data/n\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 1 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 100.0% 1 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on Evaluation data\n",
      "\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 1 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 100.0% 1 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on training data/n\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 3 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 56.666666666666664% 3 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on Evaluation data\n",
      "\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 3 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 56.666666666666664% 3 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on training data/n\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 5 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 46.666666666666664% 5 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on Evaluation data\n",
      "\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 5 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 20.0% 5 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on training data/n\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 7 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 20.0% 7 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on Evaluation data\n",
      "\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 7 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 40.0% 7 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on training data/n\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 9 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 10.0% 9 way one-shot learning accuracy \n",
      "\n",
      "Testing data accuracy on Evaluation data\n",
      "\n",
      "\n",
      "------------\n",
      "\n",
      "Evaluating model on 30 random 9 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 23.333333333333332% 9 way one-shot learning accuracy \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin the evaluation stage of the training and testing data\")\n",
    "###testing data comes from the evaluation folder\n",
    "for N in ways:\n",
    "    print(\"Testing data accuracy on testing data\\n\")\n",
    "    print(\"\\n------------\\n\")\n",
    "    val_accs.append(test_oneshot(model, N, trials, Xval, verbose=True))\n",
    "    print(\"Testing data accuracy on Training data\\n\")\n",
    "    print(\"\\n------------\\n\")\n",
    "    train_accs.append(test_oneshot(model, N, trials, X, verbose=True))\n",
    "### Again the accuracy is lower since we have not extensively trained the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the data on the One-shot classification using a Meta Learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The model will be tested against letters that the model has never encounctered. \n",
    "### We will be using a one-shot approach in which the model will have to predict whether two images are similar or different. \n",
    "nrun = 20 # number of classification runs\n",
    "fname_label = 'class_labels.txt' # where class labels are stored for each run\n",
    "\n",
    "path = \"D:\\\\Users\\\\npjos\\\\Documents\\\\Code\\\\Python\\\\all_runs\\\\\" # loading the path file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying the Demo file: \n",
    "https://github.com/brendenlake/omniglot/blob/master/python/one-shot-classification/demo_classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### The classification_run function loads the data using LoadImage and runs the model using the model.predict and \n",
    "### calculates the error. I  modified this function slightly to keep the np.shape to (1,105,105,1). This shape is required\n",
    "### for the model to run efficiently\n",
    "def classification_run(folder,f_load,f_cost,ftype='cost'):\n",
    "\t# Compute error rate for one run of one-shot classification\n",
    "\t#\n",
    "\t# Input\n",
    "\t#  folder : contains images for a run of one-shot classification\n",
    "\t#  f_load : itemA = f_load('file.png') should read in the image file and process it\n",
    "\t#  f_cost : f_cost(pair of images) should compute similarity between two images using the simaese model earlier\n",
    "\t#  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
    "\t#\n",
    "\t# Output\n",
    "\t#  perror : percent errors (0 to 100% error)\n",
    "\t# \n",
    "    assert ((ftype=='cost') | (ftype=='score'))\n",
    "\n",
    "\t# get file names\n",
    "    \n",
    "    with open(path+folder+'/'+fname_label) as f:\n",
    "        \n",
    "        content = f.read().splitlines()\n",
    "    pairs = [line.split() for line in content]\n",
    "    test_files  = [pair[0] for pair in pairs]\n",
    "    train_files = [pair[1] for pair in pairs]\n",
    "    answers_files = copy.copy(train_files)\n",
    "    test_files.sort()\n",
    "    train_files.sort()\t\n",
    "    ntrain = len(train_files)\n",
    "    ntest = len(test_files)\n",
    "\n",
    "\t# load the images (and, if needed, extract features)\n",
    "    train_items = [f_load(path+f) for f in train_files]\n",
    "    test_items  = [f_load(path+f) for f in test_files ]\n",
    "\n",
    "\t# compute cost matrix\n",
    "    costM = np.zeros((ntest,ntrain),float)\n",
    "    for i in range(ntest):\n",
    "        for c in range(ntrain):\n",
    "            pair = [test_items[i],train_items[c]] # creating a pair so that it can used by the model\n",
    "            costM[i,c] = f_cost(pair)\n",
    "    if ftype == 'cost':\n",
    "        YHAT = np.argmin(costM,axis=1)\n",
    "    elif ftype == 'score':\n",
    "        YHAT = np.argmax(costM,axis=1)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\t# compute the error rate\n",
    "    correct = 0.0\n",
    "    for i in range(ntest):\n",
    "        if train_files[YHAT[i]] == answers_files[i]:\n",
    "            correct += 1.0\n",
    "    pcorrect = 100 * correct / ntest\n",
    "    perror = 100 - pcorrect\n",
    "    return perror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### modified the image to take the shape of model of (1,105,105,1)\n",
    "def LoadImgAsPoints(fn):\n",
    "   \n",
    "    Image = io.imread(fn)\n",
    "    Image = np.stack(Image)\n",
    "    Image = np.reshape( Image, (1 , 105, 105,1))\n",
    "    return Image\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-shot classification demo with the simaese Model\n",
      " run 1 (error 100.0%)\n",
      " run 2 (error 95.0%)\n",
      " run 3 (error 95.0%)\n",
      " run 4 (error 95.0%)\n",
      " run 5 (error 100.0%)\n",
      " run 6 (error 95.0%)\n",
      " run 7 (error 100.0%)\n",
      " run 8 (error 100.0%)\n",
      " run 9 (error 95.0%)\n",
      " run 10 (error 100.0%)\n",
      " run 11 (error 100.0%)\n",
      " run 12 (error 100.0%)\n",
      " run 13 (error 100.0%)\n",
      " run 14 (error 100.0%)\n",
      " run 15 (error 95.0%)\n",
      " run 16 (error 100.0%)\n",
      " run 17 (error 100.0%)\n",
      " run 18 (error 100.0%)\n",
      " run 19 (error 100.0%)\n",
      " run 20 (error 100.0%)\n",
      " average error 98.5%\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "###Each run has 20 images and since this model is not tuned properly it has a high error rate of (98.5) \n",
    "### \n",
    "###In the demo the ModHausdorffDistance was used and that received an error rate of 38.8%. \n",
    "###Which would make that model more accepatable\n",
    "##\n",
    "print ('One-shot classification demo with the simaese Model')\n",
    "perror = np.zeros(nrun)   \n",
    "for r in range(1,nrun+1):\n",
    "    rs = str(r)\n",
    "    if len(rs)==1:\n",
    "        rs = '0' + rs\t\t\n",
    "    perror[r-1] = classification_run('run'+rs, LoadImgAsPoints, model.predict, 'score')\n",
    "    print (\" run \" + str(r) + \" (error \" + str(\tperror[r-1] ) + \"%)\")\t\n",
    "#        \n",
    "total = np.mean(perror)\n",
    "print ( \" average error \" + str(total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Function to plot images from the One shot classification folder\n",
    "def plot_img(pair,cost):\n",
    "\n",
    "    fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "    ax1.matshow(pair[0].reshape(105,105))\n",
    "    ax1.set_title(\"The test image\")\n",
    "    ax1.set_yticklabels([])\n",
    "    ax1.set_xticks([]) \n",
    "    ax1.set_yticklabels([])\n",
    "        \n",
    "    ax2.matshow(pair[1].reshape(105,105))\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_title(\"The validation tasks\")\n",
    "    ax2.set_xticks([])\n",
    "    print(\"The similarity between the two is: {0}\".format(cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modified version of classification function to include plotting function\n",
    "def classification_run_image(folder,f_load,f_cost,ftype='cost', Image = False):\n",
    "\t# Compute error rate for one run of one-shot classification\n",
    "\t#\n",
    "\t# Input\n",
    "\t#  folder : contains images for a run of one-shot classification\n",
    "\t#  f_load : itemA = f_load('file.png') should read in the image file and process it\n",
    "\t#  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
    "\t#  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
    "\t#\n",
    "\t# Output\n",
    "\t#  perror : percent errors (0 to 100% error)\n",
    "\t# \n",
    "    assert ((ftype=='cost') | (ftype=='score'))\n",
    "\n",
    "\t# get file names\n",
    "    \n",
    "    with open(path+folder+'/'+fname_label) as f:\n",
    "        #print(f)\n",
    "        content = f.read().splitlines()\n",
    "        #content = path+'/'+content\n",
    "        #print(f)\n",
    "    #print(content)\n",
    "    pairs = [line.split() for line in content]\n",
    "    test_files  = [pair[0] for pair in pairs]\n",
    "    train_files = [pair[1] for pair in pairs]\n",
    "    answers_files = copy.copy(train_files)\n",
    "    test_files.sort()\n",
    "    train_files.sort()\t\n",
    "    ntrain = len(train_files)\n",
    "    ntest = len(test_files)\n",
    "    #print(path+'/'+content)\n",
    "\t# load the images (and, if needed, extract features)\n",
    "    train_items = [f_load(path+'/'+f) for f in train_files]\n",
    "    test_items  = [f_load(path+'/'+f) for f in test_files ]\n",
    "\n",
    "\t# compute cost matrix\n",
    "    costM = np.zeros((ntest,ntrain),float)\n",
    "    for i in range(ntest):\n",
    "        for c in range(ntrain):\n",
    "            pair = [test_items[i],train_items[c]] # creating a pair so that it can used by the model\n",
    "            costM[i,c] = f_cost(pair)               \n",
    "            if (Image == True and i == 4 and c == 7):\n",
    "               plot_img(pair,costM[i,c])\n",
    "            \n",
    "    if ftype == 'cost':\n",
    "        YHAT = np.argmin(costM,axis=1)\n",
    "    elif ftype == 'score':\n",
    "        YHAT = np.argmax(costM,axis=1)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\t# compute the error rate\n",
    "    correct = 0.0\n",
    "    for i in range(ntest):\n",
    "        if train_files[YHAT[i]] == answers_files[i]:\n",
    "            correct += 1.0\n",
    "    pcorrect = 100 * correct / ntest\n",
    "    perror = 100 - pcorrect\n",
    "    return perror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between the two is: 0.9791455268859863\n",
      "run01/training/class18.png run01/training/class18.png [11  4  3  9 11 17 17  9 14  8  4 19  9  3 15  4 11  4 14 15] 17\n",
      "run01/training/class05.png run01/training/class05.png [11  4  3  9 11 17 17  9 14  8  4 19  9  3 15  4 11  4 14 15] 4\n",
      "run01/training/class16.png run01/training/class16.png [11  4  3  9 11 17 17  9 14  8  4 19  9  3 15  4 11  4 14 15] 15\n",
      "85.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### We can see that the test image and the validation tasks are different(visually), however the similarity score is high. \n",
    "### This might be due to lack of training iteration.\n",
    "error = classification_run_image('run'+'01', LoadImgAsPoints, model.predict, 'score',True)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It seems that hyperparameter tuning needs to be conducted on the Siamese  Network  inorder to improve the accuracy of the model. More specifically, the model needs to be trained for more iterations to improve accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
